[{"content":"前言 以往安装apk都是很简单的方法, Intent 里添加apk的文件就可以调用系统安装界面.后来随着谷歌对安全的重视,从Android 7开始以往的方式都不能用,然而到Android 8 又有改动,相信随着Android 的发展,以后的版本也会有改动,崇尚模块化开发的我便希望每一个细小的功能,颗粒度最少的功能都可以由一个模块来负责,然后每个项目需要这个功能时调用这个模块即可,而这个模块只需要维护好自己的兼容性问题便解决所有项目的兼容性问题.\n本文思路是提供一个笔者暂时觉得最优的方案,然后原理分析提供每个Android 版本的安装的原理思路\n最优解决方案 Android Install Apk 库 最优解决方案 : FitAndroid8\n首先笔者在解决Android 7 的安装问题时,遇到系统的私有目录访问限制问题,在解决同时感觉谷歌提供的解决方案特别麻烦,需要项目里因为针对Android 7 而增加一些文件和AndroidManifest 增加一些代码,这非常不合理,到了之后的版本或许又不一样,这些额外的代码都会带来维护的成本,后来搜索很久发现 FitAndroid7 这个库特别适合,在不用增加自己项目额外的代码同时,解决Android 7 以下的安装问题.然后到Android 8 系统时发现这个库功能失效,所以笔者便在前者的基础上稍微修改,让FitAndroid8能兼容暂时所有版本的安装,一行代码完成一个功能,不引入其他额外与项目无关的代码和文件.\n使用方式:\npublic void installApk(View view) { File file = new File(Environment.getExternalStorageDirectory(), \u0026#34;app-debug.apk\u0026#34;); Intent intent = new Intent(Intent.ACTION_VIEW); // 仅需改变这一行 FileProvider8.setIntentDataAndType(this, intent, \u0026#34;application/vnd.android.package-archive\u0026#34;, file, true); startActivity(intent); } 原理分析 笔者的习惯是把问题用最简单的方式解决,同时也需要知道其原理,以下内容为原理解析.\nAndroid 8 如何安装apk Android 8到时有了什么改变以致安装apk的方法有很大改变呢?\n在2017年8月29号的谷歌开发者博客中写道 \u0026laquo;在 Android O 中更安全地获取应用\u0026raquo;新的安装未知应用的,Android O 禁用了总是安装未知应用的选择,改为安装未知应用时提出设置的提示,减少恶意应用通过虚假的安装界面欺骗用户行为. 所以开发者需要调整AndroidManifest文件里的权限,增加 REQUEST_INSTALL_PACKAGES权限.\n\u0026lt;uses-permission android:name=\u0026#34;android.permission.REQUEST_INSTALL_PACKAGES\u0026#34; /\u0026gt; 谷歌建议是通过PackageManager canRequestPackageInstalls() 的API，查询此权限的状态,然后使用使用 ACTION_MANAGE_UNKNOWN_APP_SOURCES Intent 操作\nIntent intent = new Intent(Settings.ACTION_MANAGE_UNKNOWN_APP_SOURCES); startActivityForResult(intent, RESULT_CODE); 但是笔者不建议这样使用,因为使用 ACTION_MANAGE_UNKNOWN_APP_SOURCES Intent 操作后会跳到所有应用列表,然后从众多的应用里选择对应的APP的选择进入再打开权限,这样的用户体验不好.\n所以笔者建议不使用判断和Intent跳转.而是直接使用Intent里带apk的安装,会有提示,然后直接进入权限开关的界面,这样的体验相对好,而发现其他的主流的APP安装时也是这样.\n流程如下:\nAndroid 7 如何安装apk 这里谈谈Android 7 安装apk时有什么改变.\n参考谷歌文档 FileProvider , Setup-sharing\n从文档里知道,Android 7 开始增加安全性,文件私有化,而需要共享文件给其他程序,例如APK安装程序,需要通过FileProvider配置共享文件,配置表是基于XML文件实现,然后通过Content URI携带配置文件xml来共享文件.\n实现配置FileProvider 需要两步: 第一步: 需要配置AndroidManifest.xml清单.\n\u0026lt;provider android:name=\u0026#34;android.support.v4.content.FileProvider\u0026#34; android:authorities=\u0026#34;${applicationId}.provider\u0026#34; android:exported=\u0026#34;false\u0026#34; android:grantUriPermissions=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;!-- 元数据 --\u0026gt; \u0026lt;meta-data android:name=\u0026#34;android.support.FILE_PROVIDER_PATHS\u0026#34; android:resource=\u0026#34;@xml/file_paths\u0026#34; /\u0026gt; \u0026lt;/provider\u0026gt; 第二步:建立文件 res/xml/file_paths.xml.\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;resources\u0026gt; \u0026lt;paths\u0026gt; \u0026lt;!-- files-path： 该方式提供在应用的内部存储区的文件/子目录的文件。 它对应Context.getFilesDir返回的路径：eg:”/data/data/com.***.***/files”。 cache-path： 该方式提供在应用的内部存储区的缓存子目录的文件。 它对应Context.getCacheDir返回的路:eg:“/data/data/com.***.***/cache”； external-path： 该方式提供在外部存储区域根目录下的文件。 它对应Environment.getExternalStorageDirectory返回的路径 external-files-path: Context.getExternalFilesDir(null) external-cache-path： Context.getExternalCacheDir(String) --\u0026gt; \u0026lt;external-path name=\u0026#34;download\u0026#34; path=\u0026#34;\u0026#34; /\u0026gt; \u0026lt;/paths\u0026gt; \u0026lt;/resources\u0026gt; 而其中的 path=\u0026ldquo;\u0026ldquo;是代表根目录,也就是向共享的应用程序共享根目录以及其子目录的任何一个文件.理论上说假如共享程序是恶意程序,那它便可以获取你的应用的所有共享文件信息.\n最后准备好上面两步便可以安装文件\n/** * android7.x * @param path 文件路径 */ public void startInstallN(Context context, String path) { //参数1 上下文, 参数2 在AndroidManifest中的android:authorities值, 参数3 共享的文件 Uri apkUri = FileProvider.getUriForFile(context, Constants.AUTHORITY, new File(path)); Intent install = new Intent(Intent.ACTION_VIEW); //由于没有在Activity环境下启动Activity,设置下面的标签 install.setFlags(Intent.FLAG_ACTIVITY_NEW_TASK); //添加这一句表示对目标应用临时授权该Uri所代表的文件 install.addFlags(Intent.FLAG_GRANT_READ_URI_PERMISSION); install.setDataAndType(apkUri, \u0026#34;application/vnd.android.package-archive\u0026#34;); startActivity(install); } Android 6及以下版本 如何安装apk 最后Android 6的安装是简单\n/** *android1.x-6.x *@param path 文件的路径 */ public void startInstall(Context context, String path) { Intent install = new Intent(Intent.ACTION_VIEW); install.setDataAndType(Uri.parse(\u0026#34;file://\u0026#34; + path), \u0026#34;application/vnd.android.package-archive\u0026#34;); install.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK); context.startActivity(install); } 最后 最后简单总结, 特别认同 FitAndroid7 解决方法的理念.一行代码解决一个基础功能.\n相关引用 FitAndroid7 android安装应用(适用于各个版本) 在 Android O 中更安全地获取应用 FileProvider Setup-sharing ","date":"2018-06-07","description":"","permalink":"http://localhost:57794/posts/android-install-apk-%E5%85%BC%E5%AE%B9%E8%87%B3-android-8/","title":"Android install apk 兼容至 Android 8"},{"content":"最近工作项目里添加网络缓存时看了这个项目,内容不多,有些方法可取便记录下来\n原理 RetrofitCache 使用的方式是okhttp原有的cache机制,然后它提供了标签的方式,在Retrofit上简单实现,减少代码入侵,这是这个库的价值.\n添加拦截器 okhttp3.OkHttpClient.Builder clientBuilder=new okhttp3.OkHttpClient.Builder(); ... clientBuilder.addInterceptor(new CacheForceInterceptorNoNet()); clientBuilder.addNetworkInterceptor(new CacheInterceptorOnNet()); ... 首先复习okhttp 的 addInterceptor 和 addNetworkInterceptor 的区别\naddInterceptor是添加在与服务器连接之前和之后 addNetworkInterceptor是添加在与服务器建立连接和发起请求的之间\n具体参考 Retrofit2 + OkHttp3 配置及Interceptor原理\nCacheInterceptorOnNet CacheInterceptorOnNet是添加在与服务器建立连接和发起请求的之间\n获取 maxAge 缓存时间\n当需要缓存时\nreturn response.newBuilder() .removeHeader(\u0026#34;Cache-Control\u0026#34;) .header(\u0026#34;Cache-Control\u0026#34;, \u0026#34;public,max-age=\u0026#34;+maxAge) .removeHeader(\u0026#34;Pragma\u0026#34;) .build(); 通过header里面添加 public,max-age=maxAge来缓存,而缓存的实现由 okhttp 里面实现\nCacheForceInterceptorNoNet CacheForceInterceptorNoNet类是处理服务器连接之前和之后 功能同理,唯一不同的是在请求之前增加了是否网络连接状态的判断\nboolean forceCacheNoNet = RetrofitCache.getInstance().getCacheTime(url).isForceCacheNoNet(); if (forceCacheNoNet\u0026amp;\u0026amp;!NetUtils.isConnectNet(RetrofitCache.getInstance().getContext())){ request = request.newBuilder() .cacheControl(CacheControl.FORCE_CACHE) .build(); } 当没有网络的情况下,通过调用okhttp的Cache-Control来改变状态 具体参考 Android Okhttp网络请求之缓存控制Cache-Control\nBaseInterceptor 在bese类里,一个核心的方法是mockResponse,获取在Api里通过标签添加的模拟数据和Asset获取的模拟数据.\n而Mock类就是模拟数据的抽象类,而通过RetrofitCache.getInstance().getMockObject(url)获取 使用Java Annotation注解的方式添加\n具体参考 Java Annotation认知(包括框架图、详细介绍、示例说明)\n总结 这个第三库的本质是使用的okhttp的缓存机制,使用Java Annotation的方法灵活在API里添加注解,以往项目的注解的使用并不多,可以多用这方式提高代码的简洁性,而okhttp的源码也是不熟悉,之后可以详细研究okhttp的源码.\n","date":"2018-05-22","description":"","permalink":"http://localhost:57794/posts/retrofitcache-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","title":"RetrofitCache 源码分析"},{"content":"怎么理解一个手势,就是在屏幕上,手画一个符号就是一个手势,它代表了用户的一个意图,也就是用户希望程序做点什么,一般程序大多数是通过按钮,按钮上有对应的文字,这样进行人机交互,而手势也是很多地方会使用到,而常用的手势好像下拉刷新,用户希望列表内容下拉一下就有新的信息,双指缩放等等,一般这些手势都是跟对应的view绑定起来,而今天介绍的都是方法是可以不绑定view,直接在界面上画一个手势就可以人机交互.实现的代码可以在github上的Demo源码了解.\n这篇手势研究会大概分三部分\n手势Gesture使用方式 展示手势开发的步骤及代码实现 分析Gesture的源码及原理 使用的方式 首先我们需要把用户需要使用到的手势提前记录下来,准备一些手势的样本,在app安装时随着资源文件或者下载等方式存储到用户的手机里,当用户在app画一个手势时,就去匹配手势样本,当时样本最吻合时,就知道用户的意图,采取执行对应的功能,这样就是个很好的人机交互的方式.\n从上文使用方式,我们大概猜想到,我们需要一个东西,用来管理和读取我们已经存储的手势样本,我们还要需要这个东西可以设别用户的手势跟我们已经存储的手势进行匹配.还有,我们需一个东西在app的界面上记录用户的手势,没错,两个东西都存在,就是GestureLibrary和GestureOverlayView,这两个类就是手势开发里使用的主要两个类,通过这两个类,我们就可以实现手势开发的所有功能,是不是很简单.\n总结一下:\n提前准备好手势样本,在安装时加入到资源文件或者安装后网络下载. 需要使用手势的界面里使用GestureOverlayView记录用户的手势, 使用GestureLibrary对象对用户的手势进行监听和匹配,找到用户手势的意图,执行对应的功能 步骤及代码实现 手势库的初始化 GestureLibrary gLib=GestureLibraries.fromFile(手势库文件); gLib.load(); 这个过程是读取已经存储手势样本文件,构造出GestureLibrary实例的过程,需要第一步实现.\n对用户手势的监听 GestureOverlayView.addOnGesturePerformedListener() 使用GestureLibrary对用户的手势进行匹配 recognize(Gesture gesture)\n循环遍历返回的ArrayList对象，使用Prediction的score来匹配手势的相似度， score越高代表越匹配. Prediction.score()\n这里就是手势开发的实现的全部内容,但是作为一个程序猿,需要知其然知其所以然,就要对源码进行解剖.\n原理 手势的结构 手势是用户在屏幕上画的符号,那么手势可以简单的一笔笔画,例如一个方向的箭头(\u0026gt;),也可以多笔划,很复杂,例如一个文字.这些都手势,所以我们就知道\n手势是由一个或者多个笔画组成\n学过数学的我们都到线是由点组成的,所以\n一个手势笔画是由多个时间连续的点组成\n一个点意味着什么呢,它会固定在屏幕的某个地方,还需要时间连续不断,所以\n手势中的点包含坐标X轴和Y轴,还有时间戳\n所以我们就很容易了解手势对应的文件了\nGesturePoint : 是手势笔划中的一个点,包含X轴,Y轴的坐标,还有时间戳. GestureStroke : 手势笔划,可以理解为线,由多个点组成的. Gesture : 手势,代表用户的一个手势,可以由一个或者多个手势笔划组成. GestureStore 手势仓库,里面存储了多个手势样本\n手势的使用 使用手势的过程都是先从GestureLibrary开始,那么看看GestureLibrary的关系图.\n从图中看,GestureLibrary的实现有两种,一个File的实现,另外一个是由资源Resource实现,说明我们的手势库可有两个方向可以构造.\n然后看回GestureLibrary的源码\npublic abstract class GestureLibrary { protected final GestureStore mStore; ... } 里面只有一个对象,而所有的方法都是由这个对象实现,也就是GestureLibrary其实是GestureStore的代理类,而真正的功能其实是在GestureStore里.\nGestureStore的内容很多,首先看到的是顶部注释里有手势文件的结构内容\nNb.bytes Java type Description Header 2 bytes short File format version 4 bytes int number Number of entries Entry X bytes UTF String Entry name 4 bytes int Number of gestures Gesture 8 bytes long Gesture ID 4 bytes int Number of strokes Stroke 4 bytes int Number of points Point 4 bytes float X coordinate of the point 4 bytes float Ycoordinate of the point 8 bytes long Time stamp 从源码可以知道,GestureStore的文件格式主要组成部分,也就是GestureLibrary读取文件的格式内容,也可以考虑根据这样的格式来进行加密,假如用手势来做成一个手写输入法的软件,那么手势库一定是庞大的内容库,而且根据所有人不同的手写方式,这样的手势库一定很有价值,至于怎样加密来保护这些价值,就可以考虑每个手势的内容进行拆分来分别存储和采取不同的加密方式加密.\n然后我们再看Store对手势的读取保存\n读取和保存\n读取第一步GestureLibraries中读取手势文件\npublic boolean load() { ... mStore.load(new FileInputStream(file), true); ... } 第二步store获取文件流\npublic void load(InputStream stream, boolean closeStream) throws IOException { DataInputStream in = null; try { in = new DataInputStream((stream instanceof BufferedInputStream) ? stream : new BufferedInputStream(stream, GestureConstants.IO_BUFFER_SIZE)); ... // Read file format version number final short versionNumber = in.readShort(); switch (versionNumber) { case 1: readFormatV1(in); break; } ... } 第三步从文件流里读取文件名和手势对象(Gestire),然后存进HashMap里\n/** * 读取文件数据 * * @param in * @throws IOException */ private void readFormatV1(DataInputStream in) throws IOException { ... for (int i = 0; i \u0026lt; entriesCount; i++) { // Entry name final String name = in.readUTF(); // Number of gestures final int gestureCount = in.readInt(); final ArrayList\u0026lt;Gesture\u0026gt; gestures = new ArrayList\u0026lt;Gesture\u0026gt;(gestureCount); for (int j = 0; j \u0026lt; gestureCount; j++) { final Gesture gesture = Gesture.deserialize(in); gestures.add(gesture); classifier.addInstance(Instance.createInstance(mSequenceType, mOrientationStyle, gesture, name)); } namedGestures.put(name, gestures); } } 读取的方式是从文件流里获取到手势数据,从Gesture的deserialize方法可以知道,每一步的解析都是按照文件存储格式一步步获取数据,当然,存储也是反向一步步保存成文件流格式存储的.\n手势的匹配 这里我们再好好探求手势的设别匹配,也是我认为手势源码之中最有研究价值的一块.当把代码解析一下就会发现其实很多功能的本质就是数学问题,而这里的手势匹配的本质就是数学的线性代数.\n首先从匹配的方法入手,GestureStore.recognize()方法开始看\npublic ArrayList\u0026lt;Prediction\u0026gt; recognize(Gesture gesture) { //实例 Instance instance = Instance.createInstance(mSequenceType, mOrientationStyle, gesture, null); //归类 return mClassifier.classify(mSequenceType, mOrientationStyle, instance.vector); } recognize()方法里有两个核心,一个是根据手势对象(Gesture)来构造一个实例,二是通过mClassifier对象的classify()方法来返回一个Prediction数组.\n首先从Instance来研究.\nstatic Instance createInstance(int sequenceType, int orientationType, Gesture gesture, String label) { float[] pts; Instance instance; if (sequenceType == GestureStore.SEQUENCE_SENSITIVE) {//单笔手势 //得到一个连续点的数组 pts = temporalSampler(orientationType, gesture); instance = new Instance(gesture.getID(), pts, label); instance.normalize(); } else { pts = spatialSampler(gesture); instance = new Instance(gesture.getID(), pts, label); } return instance; } 从Instance的构造方法看是需要三个参数,id,连续点数组,和标签label.所以temporalSampler()和spatialSampler()都是把手势gesture转换为一个数组.\n但是为什么需要把一个手势转换为一个数组呢,我们都知道一条线是由无数个点,假如点太多就带来很大量的计算工作,所以我们采用生物学的抽样法.每隔固定的间隔就取一个样本,这样就减少计算量,但是太少的话就会样本集合与真实的差别就很大,所以我们去了一个适合的量作为样本数量.\nprivate static final int SEQUENCE_SAMPLE_SIZE = 16;\n我们取了样本数量为16,把任何一个手势笔划转换为均匀分割的16个点来代替.\n转换的方法就是GestureUtils.temporalSampling()\n/** * Samples a stroke temporally into a given number of evenly-distributed * points. * 代表均匀分布的点的一系列数字作为时间取样的笔划例子 * 把一个手势的笔划(连续点的线)转化为离散的点 * * @param stroke the gesture stroke to be sampled * @param numPoints the number of points 取样点的数量(越多越精确,越多消耗性能越大) * @return the sampled points in the form of [x1, y1, x2, y2, ..., xn, yn] */ public static float[] temporalSampling(GestureStroke stroke, int numPoints) { //递增量,手势笔画的长度除以需要切开的段数(离散点数 - 1) final float increment = stroke.length / (numPoints - 1); //向量长度 int vectorLength = numPoints * 2; //向量 float[] vector = new float[vectorLength];//因为向量就是取样点的内容,包含x,y坐标,所以是取样点的两倍 float distanceSoFar = 0; float[] pts = stroke.points; //上次最新的坐标 float lstPointX = pts[0]; float lstPointY = pts[1]; int index = 0; //当前坐标 float currentPointX = Float.MIN_VALUE; float currentPointY = Float.MIN_VALUE; vector[index] = lstPointX; index++; vector[index] = lstPointY; index++; int i = 0; int count = pts.length / 2; while (i \u0026lt; count) { //默认值,也是第一个运行时执行的 if (currentPointX == Float.MIN_VALUE) { i++; if (i \u0026gt;= count) { break; } currentPointX = pts[i * 2]; currentPointY = pts[i * 2 + 1]; } //坐标偏移量 float deltaX = currentPointX - lstPointX;//两个坐标点的X轴差值 float deltaY = currentPointY - lstPointY;//两个坐标点的Y轴差值 //deltaX 和 deltaY的平方和的平方根(根据三角函数,)也就是两个点的直线距离 float distance = (float) Math.hypot(deltaX, deltaY);//根据三角函数定理,X2 + Y2 = Z2 if (distanceSoFar + distance \u0026gt;= increment) {//当两个点(叠加上次循环的距离)的距离大于递增量(根据numPoints来确定的离散点的间隔距离)时执行 //比例 float ratio = (increment - distanceSoFar) / distance; float nx = lstPointX + ratio * deltaX; float ny = lstPointY + ratio * deltaY; vector[index] = nx; index++; vector[index] = ny; index++; lstPointX = nx; lstPointY = ny; distanceSoFar = 0; } else {//当两个点的距离少于间隔距离 //缓存当前的点 lstPointX = currentPointX; lstPointY = currentPointY; //当前点默认最小值 currentPointX = Float.MIN_VALUE; currentPointY = Float.MIN_VALUE; //叠加记录两点距离 distanceSoFar += distance; } } //添加剩下最后一个点的坐标 for (i = index; i \u0026lt; vectorLength; i += 2) { vector[i] = lstPointX; vector[i + 1] = lstPointY; } return vector; } 其中就使用到数学的三角函数公式,通过两个点的坐标(x,y)来计算两点距离.\n回到Instance的类\n//时间取样 private static float[] temporalSampler(int orientationType, Gesture gesture) { //离散点 float[] pts = GestureUtils.temporalSampling(gesture.getStrokes().get(0), SEQUENCE_SAMPLE_SIZE); //重心点 float[] center = GestureUtils.computeCentroid(pts); //计算弧度值(计算第一个点与重心点形成的角度的弧度值) float orientation = (float) Math.atan2(pts[1] - center[1], pts[0] - center[0]); //??? float adjustment = -orientation; if (orientationType != GestureStore.ORIENTATION_INVARIANT) { int count = ORIENTATIONS.length; for (int i = 0; i \u0026lt; count; i++) { float delta = ORIENTATIONS[i] - orientation; if (Math.abs(delta) \u0026lt; Math.abs(adjustment)) { adjustment = delta; } } } //根据中心点平移,平移到中心点在原点上 GestureUtils.translate(pts, -center[0], -center[1]); //根据调整出来的adjustment旋转数据 GestureUtils.rotate(pts, adjustment); return pts; } 除计算adjustment的方法还没理解透,欢迎读者可以继续跟我交流\n这个方法主要计算出手势的间隔点数组,然后平移到坐标原点上和调整角度,输出调整后的数组.就大概完成这个功能内容.接着我们继续看下个功能点classify.\nmClassifier这个对象的类似Learner,就是用于实现匹配功能的类,而classify的实现类在InstanceLearner这个类里,那么到底一个这么重要的方法classify到底做了什么呢?\n/** * 归类 * * @param sequenceType * @param orientationType * @param vector * @return */ @Override ArrayList\u0026lt;Prediction\u0026gt; classify(int sequenceType, int orientationType, float[] vector) { //预测对象数组 ArrayList\u0026lt;Prediction\u0026gt; predictions = new ArrayList\u0026lt;Prediction\u0026gt;(); //实例数组 ArrayList\u0026lt;Instance\u0026gt; instances = getInstances(); int count = instances.size(); //便签找到得分值的map TreeMap\u0026lt;String, Double\u0026gt; label2score = new TreeMap\u0026lt;String, Double\u0026gt;(); for (int i = 0; i \u0026lt; count; i++) { Instance sample = instances.get(i); //保证数据长度一致 if (sample.vector.length != vector.length) { continue; } //距离(与手势的差距) double distance; if (sequenceType == GestureStore.SEQUENCE_SENSITIVE) { distance = GestureUtils.minimumCosineDistance(sample.vector, vector, orientationType); } else { distance = GestureUtils.squaredEuclideanDistance(sample.vector, vector); } //权重(权重越大,代表越匹配) double weight; if (distance == 0) { //代表完全吻合 weight = Double.MAX_VALUE; } else { //取distance的倒数 weight = 1 / distance; } Double score = label2score.get(sample.label); if (score == null || weight \u0026gt; score) { label2score.put(sample.label, weight); } } for (String name : label2score.keySet()) { double score = label2score.get(name); predictions.add(new Prediction(name, score)); } //排序 Collections.sort(predictions, sComparator); return predictions; } 这个类主要做的事情就是对用户的手势和所有的已存的手势进行匹配,计算出相识度的权重,然后我们就可以根据这个权重来知道用户的手势大概是什么意思.所以这个方法最重要的内容是计算权重的方法,GestureUtils的minimumCosineDistance()和squaredEuclideanDistance()\n/** * Calculates the \u0026#34;minimum\u0026#34; cosine distance between two instances. * \u0026lt;p\u0026gt; * 最小的余弦距离 * * @param vector1 * @param vector2 * @param numOrientations the maximum number of orientation allowed * @return the distance between the two instances (between 0 and Math.PI) */ static float minimumCosineDistance(float[] vector1, float[] vector2, int numOrientations) { final int len = vector1.length; //??? float a = 0; float b = 0; for (int i = 0; i \u0026lt; len; i += 2) { a += vector1[i] * vector2[i] + vector1[i + 1] * vector2[i + 1];//(x1 * x2 + y1 * y2)叠加所有坐标 b += vector1[i] * vector2[i + 1] - vector1[i + 1] * vector2[i];//(x1 * y2 + y1 * x2)叠加所有坐标 } if (a != 0) { final float tan = b / a; //角度 final double angle = Math.atan(tan); if (numOrientations \u0026gt; 2 \u0026amp;\u0026amp; Math.abs(angle) \u0026gt;= Math.PI / numOrientations) { return (float) Math.acos(a); } else { final double cosine = Math.cos(angle); final double sine = cosine * tan; return (float) Math.acos(a * cosine + b * sine); } } else { return (float) Math.PI / 2; } } minimumCosineDistance()方法从注释来说就是实现最小的余弦距离,把用户手势点和一个样本的手势点进行叠加计算,\n/** * Calculates the squared Euclidean distance between two vectors. * * @param vector1 * @param vector2 * @return the distance */ static float squaredEuclideanDistance(float[] vector1, float[] vector2) { float squaredDistance = 0; int size = vector1.length; for (int i = 0; i \u0026lt; size; i++) { //坐标点的x轴或y轴差距 float difference = vector1[i] - vector2[i]; squaredDistance += difference * difference; } return squaredDistance / size; } squaredEuclideanDistance 的方法就是计算两点差距,然后平方和再除以数量.\nminimumCosineDistance()和squaredEuclideanDistance()的实现是知道,但是为什么要这样计算,和使用哪些数学原理还需继续深究,欢迎读者跟我进行探究.\n到这里Gesture的初步研究就差不多了,假如读者需要安卓源码的部分翻译,可以点击这里获取. 假如读者需要阅读GestureDemo可以点击这里,假如读者需要跟我交流github有邮箱联系方法\n作者信息 作者:StevenHe 博客:简书 - 可乐 工作邮箱:steven2947@163.com\n请尊重原创作者,复制引用时保留作者信息\nPromotion 七牛云推广链 蓝灯VPN - 邀请码：YJ3TKYJ ","date":"2017-05-05","description":"","permalink":"http://localhost:57794/posts/android-gesture-%E6%89%8B%E5%8A%BF%E7%A0%94%E7%A9%B6/","title":"Android Gesture 手势研究"}]